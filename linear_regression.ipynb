{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By decreasing the distance between the dependent and independent variables,<br> \n",
    "linear regression can be used to find a linear relationship between them.<br>\n",
    "<br>\n",
    "선형 회귀는 지도형 기계 학습 방법입니다.<br>\n",
    "이 방법은 순서별 범주를 분류하는 데 사용됩니다. <br>\n",
    "이번 섹션에서는 소비자가 종속변수와 독립변수 간의 관계를 <br>\n",
    "예측할 수 있는 모델을 구성하는 방법을 알아봅니다.<br>\n",
    "일반인의 용어로 독립 또는 종속 여부에 관계없이 <br>\n",
    "두 변수 간의 관계를 선형이라고 합니다. <br>\n",
    "\n",
    "Y가 종속변수이고 X가 독립변수인 경우 <br>\n",
    "이 두 변수 사이의 선형 회귀 관계는 다음과 같습니다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Y=AX+b $$\n",
    "\n",
    "- A is the **slope**\n",
    "- b is **y-intercept**\n",
    "\n",
    "**Initial State**\n",
    "\n",
    "<img src=\"./images/regression_initial.png\"> <br>\n",
    "\n",
    "**Final State**\n",
    "\n",
    "<img src=\"./images/regression_final.png\"> <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three fundamental principles that must be understood in <br>\n",
    "order to construct or practice a basic linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class\n",
    "\n",
    "필요할 때 모든 기능을 코딩하고 작성하는 것이 일반적인 관행이지만 <br>\n",
    "이는 우리의 의도가 아닙니다. 모든 코드와 함수보다는 수치 최적화 라이브러리를<br>\n",
    "작성하는 것이 더 나은 경우가 많지만, 작업을 완료하기 위해 미리 작성된 라이브러리를<br>\n",
    "기반으로 구축하면 비즈니스 이점이 향상될 수 있습니다. <br>\n",
    "우리는 이러한 목적으로 PyTorch의 nn 패키지 구현을 사용합니다.<br>\n",
    "그러기 위해서는 먼저 시트 한 장을 만들어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear layer use\n",
    "\n",
    "Each linear module computes the output from the input and retains <br>\n",
    "its own internal Tensor for weight and bias.<br>\n",
    "There are a number of other standard modules available. <br>\n",
    "We'll use a model class format, which has two key methods: <br>\n",
    "\n",
    "1. Init: This function is used to define a linear module. <br>\n",
    "2. Forward: We will train our linear regression model on the <br>\n",
    "   basis of predictions made using the forwarding process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "One of PyTorch's most important principles is the optimizer. <br>\n",
    "It's used to find the best weight for our model to fit into the dataset.<br>\n",
    "Gradient descent and backpropagation are two optimization <br>\n",
    "algorithms that optimize our weight value and best suit our model.<br>\n",
    "The torch.optim package implements a number of optimization <br>\n",
    "algorithms.<br>\n",
    "\n",
    "To use torch.optim, build an optimizer object that will change the <br>\n",
    "parameter based on the device gradient while preserving the current <br>\n",
    "state.<br>\n",
    "The item is made in the following way: <br>\n",
    "1. `Optimizer=optim.SGD(model.parameters(), lr=0.01 ,momentum=0.9 )`\n",
    "2. `Optimizer=optim.Adam([var1, var2], lr=0.0001 ))`\n",
    "\n",
    "All optimizers implement the step() process, which updates the <br>\n",
    "parameters. It can be used in two ways.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Optimizer.step()\n",
    "\n",
    "This is a rather straightforward approach that is backed by a large <br>\n",
    "number of optimizers. We may call the optimizer.step() function after <br>\n",
    "computing the gradients with the backward () process. <br>\n",
    "\n",
    "이는 수많은 최적화 프로그램의 지원을 받는 다소 간단한 접근 방식입니다.<br>\n",
    "역방향() 프로세스를 사용하여 기울기를 계산한 후 Optimizer.step() 함수를 <br>\n",
    "호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EXAMPLE\n",
    "```python\n",
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()\n",
    "    output=model(input)\n",
    "    loss=loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Optimizer.step(closure)\n",
    "Some optimization algorithms, such as LBFGS and Conjugate <br>\n",
    "Gradient, require several re-evaluations of the equation, so we must<br>\n",
    "move it in a closure that allows them to recompute your model.<br>\n",
    "\n",
    "**EXAMPLE**\n",
    "\n",
    "``` python\n",
    "for input, target in dataset:\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
